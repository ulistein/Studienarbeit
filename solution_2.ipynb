{"cells":[{"cell_type":"markdown","source":["### 0)\n","Relevant imports for this solution"],"metadata":{"id":"04phgdVRobel"}},{"cell_type":"code","source":["import os\n","import random\n","#helpful ml modules\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2\n","#Tensorflow and keras\n","import tensorflow as tf\n","from tensorflow import keras\n","#create sequential models\n","from tensorflow.keras.models import Model\n","#import the layers\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation, RandomBrightness"],"metadata":{"id":"rpkvKsvdoZg6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tb_TfeNmk0LD"},"source":["### 1)\n","- image = cv2.imread('your_image_path.jpg')\n","- (240, 320, 3)\n","- Early Assumption, this model has 3 classes and a binary output  \n","- The shape is the inputinformation for the network"]},{"cell_type":"markdown","metadata":{"id":"vND03hE4k0LH"},"source":["### 2a)\n","This model has 2 different outputs so the dataset needs 2 labels. Additionally the dataset is created with the file name from a single folder. The files are named after their color and their state (fail or not fail. Example: blue_45 is of class blue and state not fail, blue_fail_37 is of class blue and state fail). Same method for training and validation set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Opho50Xpk0LJ"},"outputs":[],"source":["# trainingset\n","# Initialize empty lists for data and labels\n","x_train = []\n","y_train_class = []\n","y_train_score = []\n","\n","# Define the path to your training dataset directory\n","training_directory = 'Datasets/train_folder'\n","\n","# List all Files in the training dataset folder and shuffle them\n","files = os.listdir(training_directory)\n","random.shuffle(files)\n","\n","# Iterate through the files and load each image into the x variable\n","# Determin their y labels via their filename\n","for x in range(0,len(files)):\n","\n","    img = cv2.imread(os.path.join(train_folder, files[x]))\n","    x_train.append(img)\n","\n","    # Determine the class\n","    if \"blue\" in files[x]:\n","        y_train_class.append(0)\n","    elif \"red\" in files[x]:\n","        y_train_class.append(1)\n","    elif \"white\" in files[x]:\n","        y_train_class.append(2)\n","    # Determine the state\n","    if \"fail\" in files[x]:\n","        y_train_score.append(False)\n","    else:\n","        y_train_score.append(True)\n","\n","# Cast the lists to numpy arrays for better processing options\n","x_train = np.array(x_train)\n","y_train_class = np.array(y_train_class)\n","y_train_score = np.array(y_train_score)\n","\n","# Cast the index to a tuple where the number at the index is 1 and the others are 0\n","# --> index of class blue is 0 --> translates to {1,0,0}\n","# --> index of class red is 1 --> translates to {0,1,0}\n","# --> index of class white is 2 --> translates to {0,0,1}\n","y_train_class = tf.keras.utils.to_categorical(y_train_class, num_classes=num_classes)\n","\n","# Print the shape of your dataset to check for the correct number of examples and size of the images\n","print(\"x_train shape\", x_train.shape)\n","print(\"y_train_class shape\", y_train_class.shape)\n","print(\"y_train_score shape\", y_train_score.shape)"]},{"cell_type":"markdown","metadata":{"id":"rkVh0HlLk0LO"},"source":["### 3)\n","This is just a suggestion, try around to get a good model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yXBS8PcYk0LP"},"outputs":[],"source":["# Building the model\n","\n","# Convolutional Layer parameters\n","num_filters = 100\n","filter_size = (3,3)\n","stride = 1\n","\n","# Pooling parameter\n","pool_size = (2,2)\n","# Density Layer parameters\n","num_dense_units = 100\n","\n","# Additional parameters\n","brightnessfactor = 0,25\n","dropout_rate = 0,1\n","shape = (240, 320, 3)\n","num_classes = 3\n","\n","# Define input layer\n","input_layer = Input(shape=shape)\n","x = input_layer\n","\n","# Augmentation Layer\n","x = RandomBrightness(brightnessfactor)(x)\n","\n","# Convolutional layers\n","x = Conv2D(num_filters, filter_size, strides=stride, activation='relu')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(dropout_rate)(x)\n","\n","x = MaxPooling2D(pool_size=pool_size)(x)\n","\n","x = Conv2D(num_filters/2, filter_size, strides=stride, activation='relu')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(dropout_rate)(x)\n","\n","x = MaxPooling2D(pool_size=pool_size)(x)\n","\n","x = Flatten()(x)\n","\n","x = Dense(num_dense_units, activation='relu')(x)\n","x = Dropout(dropout_rate)(x)\n","\n","# Output layers\n","class_output = Dense(num_classes, activation='softmax', name='class_output')(x)\n","score_output = Dense(1, activation='sigmoid', name='score_output')(x)\n","\n","# Define the model\n","model = Model(inputs=input_layer, outputs=[class_output, score_output])\n","\n","model.summary()"]},{"cell_type":"code","source":["# Compile your model\n","# Extra parameter because there are 2 outputs with separate losses\n","loss_weights = {'class_output': 0.175, 'score_output': 0.825}\n","\n","model.compile(optimizer='adam',\n","                      loss= {\n","                            'class_output': tf.keras.losses.CategoricalCrossentropy(),\n","                            'score_output': tf.keras.losses.BinaryCrossentropy()\n","                            },\n","                      metrics=['accuracy'],\n","                      loss_weights = loss_weights)"],"metadata":{"id":"k8MOF3Jbrk_5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_0AaBeTkk0LS"},"source":["### 3a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xGD4A7ROk0LT"},"outputs":[],"source":["# Define early stopping function to stop the training automatically\n","# when it does not improve the model after  number of epochs defined by patience\n","patience = 15\n","early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n","\n","# Training of the model. The Dataset here consists of 3 elements because of the model architecture.\n","num_epochs = 200 # Can be high because of early stopping\n","batch_size = 32\n","model.fit(x_train, {'class_output': y_train_class, 'score_output': y_train_score},\n","                            epochs=num_epochs,\n","                            batch_size=batch_size,\n","                            validation_data=(x_val, {'class_output': y_val_class, 'score_output': y_val_score}),\n","                            callbacks=[early_stopping])\n"]},{"cell_type":"markdown","metadata":{"id":"1vbgF_fvk0LU"},"source":["### 3b)\n","Optimize Options:\n","- Dataaugmentation -> Extra layers for augmentation (Example: Randombrightness)\n","- Regularization -> Dropout or L2\n","- Train longer -> more epochs\n","- increase the complexity of the network -> more Layers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awNbIiKAk0LV"},"outputs":[],"source":["model.evaluate(x_val,{'class_output': y_val_class, 'score_output': y_val_score}, batch_size = batch_size)"]},{"cell_type":"markdown","metadata":{"id":"DBI4ryytk0LW"},"source":["### 4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ubnpvhc2k0LX"},"outputs":[],"source":["# Keras Layers for Augmentation\n","x = RandomBrightness(brightnessfactor)(x)\n","# Layer for Regularization\n","x = Dropout(dropout_rate)(x)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}