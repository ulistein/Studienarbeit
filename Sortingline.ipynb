{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This Workshop is created to give an introduction into the building of Convolutional Neural Network with the help of Tensorflow. \n",
    "## Goal\n",
    "The Goal is to provide a step by step solution to build a model, which seperates good an bad parts on a end-of-line model\n",
    "\n",
    "![Alt Text](pictures/foto_Modell.png)\n",
    "\n",
    "## steps\n",
    "The workshop will include multiple steps to create a model\n",
    "- inspecting the trainingsdata\n",
    "- load the data and label it\n",
    "- build a simple model\n",
    "- improve the model\n",
    "- test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "To work create a model and work with it a few imports are necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#helpful ml modules\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "#Tensorflow and keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#create sequential models\n",
    "from tensorflow.keras.models import Sequential\n",
    "#import the layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, InputLayer, Dropout\n",
    "#datagenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#augmentation\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) inspect the datasets\n",
    "There are two trainingsets in this project, one with 4 subfolders and one with 6 subfolders.\n",
    "- Which assumptions can you make for the model architecture with this information?\n",
    "- Load the shape of an image using the cv2 module\n",
    "- which information can you take away from the shape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "#load the image image = cv2...\n",
    "image = \n",
    "#print the image shape\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) creating datasets\n",
    "To use the given datasets to train a network they need to be loaded. You can do this using cv2 or the keras ImageDataGenrator. Create one Trainings and dataset using both solutions. Decide if you want 4 or 6 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a) create a dataset using cv2 and for loops\n",
    "- how many lists do you need?\n",
    "- how can you get to the images?\n",
    "- What functions do you need from cv2\n",
    "- how are you going to label your data? (hint: look at the files or folders)\n",
    "- how will you normalize the data?\n",
    "- print the number of images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 840\n",
      "Number of training labels: 840\n"
     ]
    }
   ],
   "source": [
    "# trainingsset\n",
    "# Initialize empty lists for data and labels\n",
    "\n",
    "# Define the path to your training dataset directory\n",
    "training_directory = \n",
    "\n",
    "# Iterate over subdirectories (classes) in the training dataset directory\n",
    "for class_name in os.listdir(training_directory):\n",
    "    class_dir = os.path.join(training_directory, class_name)\n",
    "\n",
    "    # Iterate over image files in the class directory\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "\n",
    "        # Load image\n",
    "\n",
    "        # Normalize pixel values\n",
    "\n",
    "        # Append image to data list\n",
    "\n",
    "\n",
    "        # Assign numerical label based on filename.  Here is a if statement needed\n",
    "\n",
    "\n",
    "# Print the loaded data and labels\n",
    "print(\"Number of training samples:\", len(x_train))\n",
    "print(\"Number of training labels:\", len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected:\\\n",
    "Number of training samples: 840\\\n",
    "Number of training labels: 840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 360\n",
      "Number of test labels: 360\n"
     ]
    }
   ],
   "source": [
    "# testset\n",
    "# Initialize empty lists for data and labels\n",
    "\n",
    "# Define the path to your training dataset directory\n",
    "training_directory = \n",
    "\n",
    "# Iterate over subdirectories (classes) in the training dataset directory\n",
    "for class_name in os.listdir(training_directory):\n",
    "    class_dir = os.path.join(training_directory, class_name)\n",
    "\n",
    "    # Iterate over image files in the class directory\n",
    "    for image_name in os.listdir(class_dir):\n",
    "        image_path = os.path.join(class_dir, image_name)\n",
    "\n",
    "        # Load image\n",
    "\n",
    "        # Normalize pixel values\n",
    "\n",
    "        # Append image to data list\n",
    "\n",
    "        # Assign numerical label based on filename. Here is a if statement needed\n",
    "\n",
    "\n",
    "# Print the loaded data and labels\n",
    "print(\"Number of test samples:\", len(x_test))\n",
    "print(\"Number of test labels:\", len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected:\\\n",
    "Number of training samples: 360\\\n",
    "Number of training labels: 360\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b) create a dataset using ImageDataGenerator\n",
    "- What functions do you need from ImageDatagenerator\n",
    "- how are you going to label your data? (hint: look at the files or folders)\n",
    "- how will you normalize the data?\n",
    "- which configurations can be enabled?\n",
    "- print the class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 840 images belonging to 6 classes.\n",
      "Class indices: {'blue': 0, 'blue_fail': 1, 'red': 2, 'red_fail': 3, 'white': 4, 'white_fail': 5}\n"
     ]
    }
   ],
   "source": [
    "#trainingset\n",
    "# traindirectory\n",
    "data_dir_train = ''\n",
    "\n",
    "# generate Datengeneratoren\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "# Training Datengenerator\n",
    "train_generator = datagen.\n",
    "\n",
    "class_indices = train_generator.class_indices\n",
    "\n",
    "# Print the class indices\n",
    "print(\"Class indices:\", class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected:\\\n",
    "Found 840 images belonging to 4 classes.\n",
    "Class indices: {'blue': 0, 'fail': 1, 'red': 2, 'white': 3}\\\n",
    "OR\\\n",
    "Found 840 images belonging to 6 classes.\n",
    "Class indices: {'blue': 0, 'blue_fail': 1, 'red': 2, 'red_fail': 3, 'white': 4, 'white_fail': 5}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 images belonging to 6 classes.\n",
      "Class indices: {'blue': 0, 'blue_fail': 1, 'red': 2, 'red_fail': 3, 'white': 4, 'white_fail': 5}\n"
     ]
    }
   ],
   "source": [
    "# Testset\n",
    "# testdirectory\n",
    "data_dir_eval = ''\n",
    "\n",
    "# configure evaluationgenerator\n",
    "eval_datagen = ImageDataGenerator()\n",
    "\n",
    "# create a evaluationset\n",
    "eval_generator = eval_datagen.\n",
    ")\n",
    "class_indices = eval_generator.class_indices\n",
    "\n",
    "# Print the class indices\n",
    "print(\"Class indices:\", class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expected:\\\n",
    "Found 360 images belonging to 4 classes.\n",
    "Class indices: {'blue': 0, 'fail': 1, 'red': 2, 'white': 3}\\\n",
    "OR\\\n",
    "Found 360 images belonging to 6 classes.\n",
    "Class indices: {'blue': 0, 'blue_fail': 1, 'red': 2, 'red_fail': 3, 'white': 4, 'white_fail': 5}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create a Classification model\n",
    "Start with a classification model. This should be able to predict between the Classes you chose (4 or 6). Start to utilize the imported layers of Keras.\n",
    "- What is the Input dimension?\n",
    "- Where do you configure the Input?\n",
    "- How is the last Layer configured?\n",
    "- Which metric and lossfuntion do you choose?\n",
    "- where is the flatten layer needed?\n",
    "- start with the sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start to create a Basic sequential model\n",
    "model = Sequential()\n",
    "#start adding layers here\n",
    "\n",
    "#compile your model\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='', metrics=[''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a) train the model\n",
    "- option1: use the two lists generated with the cv2 workflow (think about the batch size)\n",
    "- option2: use the datagen sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit('''put your traingsset here''', epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b)evaluate the model\n",
    "Evaluate your model, again there are two options.\n",
    "- How is the accuracy?\n",
    "- How can it be optimized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate('''put your traingsset here''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Choose optimization methods if needed \n",
    "Underfitting (your model cant get a good trainings accuracy)?:\n",
    "- Research dataaugmentation and add it to either your model or in the dataset (ImageDataGenerator needs to be reconfigured)\n",
    "- Increase the amount of epochs\n",
    "- Change the Architecture (More Dense Layers, more Conv2d Layers...)\n",
    "\n",
    "### \n",
    "Overfitting (your model has a good training accuracy, bad a bad validation accuracy)\n",
    "- Research Dropoutlayers and add them to your model\n",
    "- research Keras Callback and early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Export the model to .tflite\n",
    "if your model has achieved a good validation accuracy you can export it to a tflite model. This can then be loaded to the controller of the conveyor belt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Speichere das tflite-Modell\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) load the model on the Controller\n",
    "- open the RoboCoding App\n",
    "- connect the Controller to the Computer with USB\n",
    "- enter the IP 192.168.7.2 in the Browser\n",
    "- Username: ft Password: fischertechnik\n",
    "- copy your tflite model to custom/\n",
    "- change line 19 in the process.py file of the RoboCoding project to your model\n",
    "- load the programm on the Controller\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
